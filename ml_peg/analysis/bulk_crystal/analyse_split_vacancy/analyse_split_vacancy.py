"""Analyse split vacancy benchmark."""

from __future__ import annotations

from pathlib import Path

from ase.io import read
import numpy as np
from pymatgen.analysis.structure_matcher import StructureMatcher
from pymatgen.core import Structure
import pytest
from scipy.stats import spearmanr
from tqdm.auto import tqdm

from ml_peg.analysis.utils.decorators import build_table, plot_parity
from ml_peg.analysis.utils.utils import load_metrics_config, mae
from ml_peg.app import APP_ROOT
from ml_peg.calcs import CALCS_ROOT
from ml_peg.models.get_models import get_model_names
from ml_peg.models.models import current_models

MODELS = get_model_names(current_models)
CALC_PATH = CALCS_ROOT / "bulk_crystal" / "split_vacancy" / "outputs"
OUT_PATH = APP_ROOT / "data" / "bulk_crystal" / "split_vacancy"

METRICS_CONFIG_PATH = Path(__file__).with_name("metrics.yml")
DEFAULT_THRESHOLDS, DEFAULT_TOOLTIPS, DEFAULT_WEIGHTS = load_metrics_config(
    METRICS_CONFIG_PATH
)

STRUCTURE_MATCHER = StructureMatcher()


def is_same_atoms(atoms_1, atoms_2) -> float:
    """
    Determine if two ASE Atoms are the same.

    Parameters
    ----------
    atoms_1, atoms_2
        ASE Atoms objects.

    Returns
    -------
    bool
        True if same structure.
    """
    return STRUCTURE_MATCHER.fit(
        Structure.from_ase_atoms(atoms_1), Structure.from_ase_atoms(atoms_2)
    )


def get_hoverdata() -> tuple[list, list, list]:
    """
    Get hover data.

    Returns
    -------
    tuple[list, list, list ]
        Tuple of Materials Project IDs, bulk formulae and vacant cations.
    """
    # TODO: RMSD could be good hoverdata?
    # TODO: add cell charge?
    mp_ids = []
    formulae = []
    vacant_cations = []

    model_dir = model_dir = CALC_PATH / MODELS[0]
    for material_dir in tqdm(list(model_dir.iterdir())):
        split_dir_name = material_dir.stem.split("-")
        bulk_formula = split_dir_name[0]
        mp_id = f"mp-{split_dir_name[-1]}"

        cation_dirs = [
            p for p in material_dir.iterdir() if p.is_dir()
        ]  # skip pristine supercell.xyz files if present (not used)

        for cation_dir in cation_dirs:
            cation = cation_dir.stem

            mp_ids.append(mp_id)
            formulae.append(bulk_formula)
            vacant_cations.append(cation)

    return mp_ids, formulae, vacant_cations


MP_IDS, BULK_FORMULAE, VACANT_CATIONS = get_hoverdata()


@pytest.fixture  # cache outputs
def build_results() -> tuple[dict[str, list], dict[str, list], dict[str, list]]:
    """
    Iterate through bulk-cation pairs calculating results.

    Returns
    -------
    tuple[dict[str, float], dict[str, float], dict[str, float]]
        Tuple of metrics.
    """
    # preference_energy_threshold = 0  # TODO: confirm

    result_formation_energy = {"ref": []} | {
        mlip: [] for mlip in MODELS
    }  # formation energy for every material-cation pair
    result_spearmans_coefficient = {
        mlip: [] for mlip in MODELS
    }  # spearmans coefficient for every material-cation pair
    result_same_structure = {
        mlip: [] for mlip in MODELS
    }  # DFT-MLIP structure match for every material-cation pair
    # TODO: investigate Kendall rank correlation
    result_rmsd = {mlip: [] for mlip in MODELS}

    ref_stored = False
    for model_name in MODELS:
        model_dir = CALC_PATH / model_name

        if not model_dir.exists():
            continue

        for material_dir in tqdm(list(model_dir.iterdir())):
            cation_dirs = [
                p for p in material_dir.iterdir() if p.is_dir()
            ]  # skip pristine supercell.xyz files if present (not used)

            for cation_dir in tqdm(cation_dirs, leave=False):
                # cation = cation_dir.stem TODO: save structures for visualization

                nv_xyz_path = cation_dir / "normal_vacancy.xyz.gz"
                sv_xyz_path = cation_dir / "split_vacancy.xyz.gz"

                if not (nv_xyz_path.exists() and sv_xyz_path.exists()):
                    raise ValueError  # TODO: remove

                nv_atoms_list = read(nv_xyz_path, ":")
                sv_atoms_list = read(sv_xyz_path, ":")

                if not ref_stored:
                    ref_nv_energies = [
                        float(at.info["ref_energy"]) for at in nv_atoms_list
                    ]
                    ref_sv_energies = [
                        float(at.info["ref_energy"]) for at in sv_atoms_list
                    ]

                    ref_sv_formation_energy = min(ref_sv_energies) - min(
                        ref_nv_energies
                    )
                    # ref_sv_preferred = (
                    #     ref_sv_formation_energy < preference_energy_threshold
                    # ) # TODO: F1 score

                    result_formation_energy["ref"].append(ref_sv_formation_energy)

                    ref_cation_dir = (
                        CALC_PATH / "ref" / material_dir.stem / cation_dir.stem
                    )
                    ref_nv_atoms_list = read(
                        ref_cation_dir / "normal_vacancy.xyz.gz", ":"
                    )
                    ref_sv_atoms_list = read(
                        ref_cation_dir / "split_vacancy.xyz.gz", ":"
                    )

                nv_energies = [float(at.info["relaxed_energy"]) for at in nv_atoms_list]
                sv_energies = [float(at.info["relaxed_energy"]) for at in sv_atoms_list]

                # calculate metrics
                sv_formation_energy = min(sv_energies) - min(nv_energies)
                # sv_preferred = sv_formation_energy < preference_energy_threshold

                spearmans_coefficient = spearmanr(
                    [float(at.info["initial_energy"]) for at in nv_atoms_list]
                    + [float(at.info["initial_energy"]) for at in sv_atoms_list],
                    ref_sv_energies + ref_nv_energies,
                ).statistic

                same_structure_list = []
                for ref_atoms, mlip_atoms in zip(
                    ref_nv_atoms_list, nv_atoms_list, strict=False
                ):
                    same_structure_list.append(is_same_atoms(ref_atoms, mlip_atoms))
                for ref_atoms, mlip_atoms in zip(
                    ref_sv_atoms_list, sv_atoms_list, strict=False
                ):
                    same_structure_list.append(is_same_atoms(ref_atoms, mlip_atoms))

                # add metrics to dicts
                result_formation_energy[model_name].append(sv_formation_energy)
                result_spearmans_coefficient[model_name].append(spearmans_coefficient)
                result_same_structure[model_name].extend(same_structure_list)

        ref_stored = False
    return result_formation_energy, result_spearmans_coefficient, result_same_structure


@pytest.fixture
@plot_parity(
    filename=OUT_PATH / "figure_formation_energies_dft.json",
    title="Split vacancy",
    x_label="Predicted Split Vacancy Formation Energy / eV",
    y_label="DFT Split Vacancy Formation Energy / eV",
    hoverdata={
        "Materials Project ID": MP_IDS,
        "Formula": BULK_FORMULAE,
        "Vacant Cation": VACANT_CATIONS,
    },
)
def formation_energies_dft(build_results) -> dict[str, list]:
    """
    Get DFT and predicted formation energies.

    Parameters
    ----------
    build_results
        Tuple of results dictionaries.

    Returns
    -------
    dict[str, list]
        Dictionary of DFT and predicted formation energies.
    """
    result_formation_energies, _, _ = build_results
    return result_formation_energies


@pytest.fixture
def formation_energy_dft_mae(formation_energies_dft) -> dict[str, float]:
    """
    Get mean absolute error for split-vancacy formation energies compared to DFT.

    Parameters
    ----------
    formation_energies_dft
        Dictionary of DFT and predicted formation energies.

    Returns
    -------
    dict[str, float]
        Dictionary of formation energy MAEs for all models.
    """
    results = {}
    for model_name in MODELS:
        results[model_name] = mae(
            formation_energies_dft["ref"], formation_energies_dft[model_name]
        )
    return results


@pytest.fixture
def spearmans_coefficient_dft_mean(build_results) -> dict[str, float]:
    """
    Get mean spearmans coefficient between DFT and MLIP relaxed structures.

    Parameters
    ----------
    build_results
        Tuple of results dictionaries.

    Returns
    -------
    dict[str, float]
        Dictionary of mean Spearman's coefficients for all models.
    """
    _, result_spearmans_coefficient, _ = build_results

    results = {}
    for model_name in MODELS:
        results[model_name] = float(np.mean(result_spearmans_coefficient[model_name]))
    return results


@pytest.fixture
def same_structure_accuracy(build_results) -> dict[str, float]:
    """
    Get RMSD between DFT and MLIP relaxed structures.

    Parameters
    ----------
    build_results
        Tuple of results dictionaries.

    Returns
    -------
    dict[str, float]
        Dictionary of mean relaxed structure RMSDs for all models.
    """
    _, _, result_same_structure = build_results

    results = {}
    for model_name in MODELS:
        results[model_name] = float(np.mean(result_same_structure[model_name]))
    return results


@pytest.fixture
@build_table(
    filename=OUT_PATH / "split_vacancy_metrics_table.json",
    metric_tooltips=DEFAULT_TOOLTIPS,
    thresholds=DEFAULT_THRESHOLDS,
)
def metrics(
    formation_energy_dft_mae: dict[str, float],
    spearmans_coefficient_dft_mean: dict[str, float],
    rmsd_dft_mean: dict[str, float],
) -> dict[str, dict]:
    """
    Get all new benchmark metrics.

    Parameters
    ----------
    formation_energy_dft_mae
        Split vancancy formation energy MAE for all models.
    spearmans_coefficient_dft_mean
        Spearman's coefficient mean for all models.
    rmsd_dft_mean
        RMSD for all models.

    Returns
    -------
    dict[str, dict]
        Metric names and values for all models.
    """
    # print(formation_energy_dft_mae)
    return {
        "MAE": formation_energy_dft_mae,
        "Mean Spearman's Coefficient": spearmans_coefficient_dft_mean,
        "Structure Accuracy": rmsd_dft_mean,
    }


def test_new_benchmark(metrics: dict[str, dict]) -> None:
    """
    Run new benchmark analysis.

    Parameters
    ----------
    metrics
        All new benchmark metric names and dictionary of values for each model.
    """
    return
